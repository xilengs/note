## RSMProp优化器

RSMProp(Root Mean Square Propagation optimizer) 均方根传播优化器。在标准梯度下降优化器上进行了改进。

在训练神经网络时，学习率是一直不变的，如果学习率很大，这会导致梯度大的参数在最优值附近来回震荡，不能收敛；如果学习率很小，会导致梯度小的参数学习停滞不前。

RSMProp就是让每个参数都有自适应的学习率，让梯度值大的参数学习率相对小一点，让梯度值小的参数的学习率相对大一点，这样训练过程就会稳定且快速。

RSMProp记录**每个参数梯度平方的指数加权平均值S**，更新参数时的梯度除以S。

以参数w为例，首先计算梯度值：
$g_w = \frac{\partial loss}{\partial w}$
计算$g_w^2$指数加权平均值：
$S_w = \beta S_w + (1 - \beta)g_w^2$
更新参数，Ir是学习率：
$w = w - \frac{lr}{\sqrt{S_w} + \epsilon}g_w$
其中$\beta$一般取0.9。$\epsilon$是为了防止除0，加一个很小的数，一般是1e-8。