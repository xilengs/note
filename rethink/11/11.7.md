## 迁移学习

### 1.神经网络中的迁移学习

1. **加载预训练模型**：获取已在ImageNet上训练好的$ResNet$模型及其权重
2. **冻结特征提取层**：锁定$ResNet$中负责特征提取的层（通常是除了最后的分类层之外的所有层），使其参数在后续训练中保持不变
3. **替换分类头**：移除$ResNet$原有的1000类分类层，根据分类任务的需求，创建一个新的、随机初始化的分类层。
4. **微调分类头**：使用标注好的图像数据集进行训练，在训练过程中，**只更新新添加的分类层的参数**，而预训练的特征提取层参数保持冻结

### 2. 迁移学习的一般原则和策略

迁移学习的核心流程是：首先在一个具有大量标注数据的数据集上训练出一个基础模型（预训练模型）。然后根据目标任务的特点和数据量，采取不同的迁移策略：

- **任务相关性是关键**：新任务必须与预训练模型的源任务领域相近。任务越相似，迁移学习效果越好。
- 策略取决于目标数据量：
  - **数据很少（如几百张）**：仅替换预训练模型的最后一层（分类头），创建一个新的、适应目标类别数的分类层。冻结网络中除新分类层外的所有参数。训练时只更新分类层的参数。使用较小的学习率（如1e-4，1e-5）。
  - **数据量适中（几千张）**：替换分类头，同时解冻预训练模型靠近输出端的最后几层。训练时允许解冻层的参数以及新分类头的参数一起更新。其他层参数保持冻结。
  - **数据量较大（几万张）**：替换分类头，并允许整个网络的参数（包括预训练部分）在目标数据集上进行更新（微调）。此时可以使用稍大的学习率，或采用学习率衰减策略。